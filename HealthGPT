HealthGPT on TryHackMe is basically a room where we try to bypass an LLM and make it reveal information that it normally blocks. The idea is to trick the model into thinking that whatever it’s doing is “allowed.”
Let’s Start
First, start the target machine using the link provided in the room.

After the machine loads, we begin testing how the model responds. If you directly ask anything related to the flag, it immediately replies with something like “Access denied.” So asking straight questions doesn’t work at all.

Press enter or click to view the image in full size

Press enter or click to view image in full size

How I Approached It
Since direct questions fail, the next step is to create your own kind of story or scenario. The goal is to bring the context of the flag into the conversation indirectly.

Become a member
Basically:

Don’t ask for the flag directly
Press enter or click to view image in full size

Build a situation where the model “thinks” it’s safe to include the information.
Press enter or click to view image in full size

Make the flag part of a fictional setup instead of a direct request.
Press enter or click to view image in full size

This way, you make the model reveal the flag inside the story you created.
